{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Grasp and Lift EEG analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/grasp-and-lift-eeg-detection/data?train.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.bci2000.org/wiki/index.php/User_Tutorial:Introduction_to_the_Mu_Rhythm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://www.bci2000.org/wiki/images/thumb/7/70/MuRhythmModulation.PNG/471px-MuRhythmModulation.PNG\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image \n",
    "Image(url='http://www.bci2000.org/wiki/images/thumb/7/70/MuRhythmModulation.PNG/471px-MuRhythmModulation.PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'mne'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c24b3bd245cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRawArray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_montage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconcatenate_epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'mne'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Jun 29 14:00:37 2015\n",
    "\n",
    "@author: alexandrebarachant\n",
    "\n",
    "During a hand movement, the mu (~10Hz) and beta (~20Hz) oscillations are suppressed \n",
    "over the contralateral motor cortex, i.e. we can observe a reduction of the \n",
    "signal power in the corresponding frequency band. This effect is know as \n",
    "Event Related Desynchronization.\n",
    "\n",
    "I used MNE python to epoch signal corresponding to the hand movement, by assuming that \n",
    "the hand movement occur before the 'Replace' event.\n",
    "\n",
    "Using Common spatial patterns algorithm, i extract spatial filters that maximize \n",
    "the difference of variance during and after the movement, and then visualize the \n",
    "corresponding spectrum. \n",
    "\n",
    "For each subject, we should see a spot over the electrode C3 (Left motor cortex,\n",
    "corresponding to a right hand movement), and a decrease of the signal power in \n",
    "10 and 20 Hz during the movement (by reference to after the movement).\n",
    "\n",
    "Each subject has a different cortex organization, and a different apha and beta \n",
    "peak. The CSP algorithm is also sensitive to artefacts, so it could give eronous \n",
    "maps (for example subject 5 seems to trig on eye movements)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mne.io import RawArray\n",
    "from mne.channels import read_montage\n",
    "from mne.epochs import concatenate_epochs\n",
    "from mne import create_info, find_events, Epochs\n",
    "from mne.viz.topomap import _prepare_topo_plot, plot_topomap\n",
    "from mne.decoding import CSP\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.cross_validation import cross_val_score, LeaveOneLabelOut\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from scipy.signal import welch\n",
    "from mne import pick_types\n",
    "\n",
    "def creat_mne_raw_object(fname):\n",
    "    \"\"\"Create a mne raw instance from csv file\"\"\"\n",
    "    # Read EEG file\n",
    "    data = pd.read_csv(fname)\n",
    "    \n",
    "    # get chanel names\n",
    "    ch_names = list(data.columns[1:])\n",
    "    \n",
    "    # read EEG standard montage from mne\n",
    "    montage = read_montage('standard_1005',ch_names)\n",
    "\n",
    "    # events file\n",
    "    ev_fname = fname.replace('_data','_events')\n",
    "    # read event file\n",
    "    events = pd.read_csv(ev_fname)\n",
    "    events_names = events.columns[1:]\n",
    "    events_data = np.array(events[events_names]).T\n",
    "    \n",
    "    # concatenate event file and data\n",
    "    data = np.concatenate((1e-6*np.array(data[ch_names]).T,events_data))        \n",
    "    \n",
    "    # define channel type, the first is EEG, the last 6 are stimulations\n",
    "    ch_type = ['eeg']*len(ch_names) + ['stim']*6\n",
    "    \n",
    "    # create and populate MNE info structure\n",
    "    ch_names.extend(events_names)\n",
    "    info = create_info(ch_names,sfreq=500.0, ch_types=ch_type, montage=montage)\n",
    "    info['filename'] = fname\n",
    "    \n",
    "    # create raw object \n",
    "    raw = RawArray(data,info,verbose=False)\n",
    "    return raw\n",
    "\n",
    "subjects = range(1,12)\n",
    "auc = []\n",
    "for subject in subjects:\n",
    "    epochs_tot = []\n",
    "    \n",
    "    #eid = 'HandStart'\n",
    "    fnames =  glob('../input/train/subj%d_series*_data.csv' % (subject))\n",
    "    \n",
    "    session = []\n",
    "    y = []\n",
    "    for i,fname in enumerate(fnames):\n",
    "      \n",
    "        # read data \n",
    "        raw = creat_mne_raw_object(fname)\n",
    "        \n",
    "        # pick eeg signal\n",
    "        picks = pick_types(raw.info,eeg=True)\n",
    "        \n",
    "        # Filter data for alpha frequency and beta band\n",
    "        # Note that MNE implement a zero phase (filtfilt) filtering not compatible\n",
    "        # with the rule of future data.\n",
    "        raw.filter(7,35, picks=picks, method='iir', n_jobs=-1, verbose=False)\n",
    "        \n",
    "        # get event posision corresponding to Replace\n",
    "        events = find_events(raw,stim_channel='Replace', verbose=False)\n",
    "        # epochs signal for 1.5 second before the movement\n",
    "        epochs = Epochs(raw, events, {'during' : 1}, -2, -0.5, proj=False,\n",
    "                        picks=picks, baseline=None, preload=True,\n",
    "                        add_eeg_ref=False, verbose=False)\n",
    "        \n",
    "        epochs_tot.append(epochs)\n",
    "        session.extend([i]*len(epochs))\n",
    "        y.extend([1]*len(epochs))\n",
    "        \n",
    "        # epochs signal for 1.5 second after the movement, this correspond to the \n",
    "        # rest period.\n",
    "        epochs_rest = Epochs(raw, events, {'after' : 1}, 0.5, 2, proj=False,\n",
    "                        picks=picks, baseline=None, preload=True,\n",
    "                        add_eeg_ref=False, verbose=False)\n",
    "        \n",
    "        # Workaround to be able to concatenate epochs\n",
    "        epochs_rest.times = epochs.times\n",
    "        \n",
    "        epochs_tot.append(epochs_rest)\n",
    "        session.extend([i]*len(epochs_rest))\n",
    "        y.extend([-1]*len(epochs_rest))\n",
    "        \n",
    "    #concatenate all epochs\n",
    "    epochs = concatenate_epochs(epochs_tot)\n",
    "    \n",
    "    # get data \n",
    "    X = epochs.get_data()\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # run CSP\n",
    "    csp = CSP(reg='lws')\n",
    "    csp.fit(X,y)\n",
    "    \n",
    "    # compute spatial filtered spectrum\n",
    "    po = []\n",
    "    for x in X:\n",
    "        f,p = welch(np.dot(csp.filters_[0,:].T,x), 500, nperseg=512)\n",
    "        po.append(p)\n",
    "    po = np.array(po)\n",
    "    \n",
    "    # prepare topoplot\n",
    "    _,epos,_,_,_ = _prepare_topo_plot(epochs,'eeg',None)\n",
    "    \n",
    "    # plot first pattern\n",
    "    pattern = csp.patterns_[0,:]\n",
    "    pattern -= pattern.mean()\n",
    "    ix = np.argmax(abs(pattern))\n",
    "    # the parttern is sign invariant.\n",
    "    # invert it for display purpose\n",
    "    if pattern[ix]>0:\n",
    "        sign = 1.0\n",
    "    else:\n",
    "        sign = -1.0\n",
    "    \n",
    "    fig, ax_topo = plt.subplots(1, 1, figsize=(12, 4))\n",
    "    title = 'Spatial Pattern'\n",
    "    fig.suptitle(title, fontsize=14)\n",
    "    img, _ = plot_topomap(sign*pattern,epos,axis=ax_topo,show=False)\n",
    "    divider = make_axes_locatable(ax_topo)\n",
    "    # add axes for colorbar\n",
    "    ax_colorbar = divider.append_axes('right', size='5%', pad=0.05)\n",
    "    plt.colorbar(img, cax=ax_colorbar)\n",
    "    \n",
    "    # plot spectrum\n",
    "    fix = (f>7) & (f<35)\n",
    "    ax_spectrum = divider.append_axes('right', size='300%', pad=1.2)\n",
    "    ax_spectrum.plot(f[fix],np.log(po[y==1][:,fix].mean(axis=0).T),'-r',lw=2)\n",
    "    ax_spectrum.plot(f[fix],np.log(po[y==-1][:,fix].mean(axis=0).T),'-b',lw=2)\n",
    "    ax_spectrum.set_xlabel('Frequency (Hz)')\n",
    "    ax_spectrum.set_ylabel('Power (dB)')\n",
    "    plt.grid()\n",
    "    plt.legend(['during','after'])\n",
    "    plt.title('Subject %d' % subject)\n",
    "    plt.show()\n",
    "    plt.savefig('spatial_pattern_subject_%d.png' % subject ,bbox_inches='tight')\n",
    "    \n",
    "    # run cross validation\n",
    "    clf = make_pipeline(CSP(),LogisticRegression())\n",
    "    cv = LeaveOneLabelOut(session)\n",
    "    auc.append(cross_val_score(clf,X,y,cv=cv,scoring='roc_auc').mean())\n",
    "    print(\"Subject %d : AUC cross val score : %.3f\" % (subject,auc[-1]))\n",
    "\n",
    "auc = pd.DataFrame(data=auc,index=subjects,columns=['auc'])\n",
    "auc.to_csv('cross_val_auc.csv')\n",
    "plt.figure(figsize=(4,4))\n",
    "auc.plot(kind='bar',y='auc')\n",
    "plt.xlabel('Subject')\n",
    "plt.ylabel('AUC')\n",
    "plt.title('During Vs. After classification')\n",
    "plt.savefig('cross_val_auc.png' ,bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
